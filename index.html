<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xu Li</title>
    <link rel="stylesheet" href="minimal-styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</head>
<body>
    <header>
        <nav>
            <ul class="nav-links">
                <li><a href="#home">Home</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="cv.html">CV</a></li>
            </ul>
            <div class="theme-toggle">
                <i class="fas fa-moon"></i>
            </div>
        </nav>
    </header>

    <main>
        <section id="home" class="intro">
            <div class="container">
                <div class="profile">
                    <div class="intro-text">
                        <p>Hi, I'm Xu Li (ÊùéÊó≠), a computer science student at Northeastern University Boston, MA.</p>
    
                        <p>I focus on <strong>multimodal agent robustness</strong>, with particular interest in how agents handle complex contexts during <strong>learning</strong> and <strong>deployment</strong>.</p>

                        <p>I conduct research on Web Agents and their safety at <a href="https://wyshi.github.io/group.html" target="_blank">Chats Lab</a> under the supervision of Prof. Weiyan Shi.</p>

                        <p>I also collaborate with <a href="https://ai4eps.github.io/homepage/" target="_blank">AI4EPS</a> at UC Berkeley, led by Prof. Weiqiang Zhu, focusing on foundation models for seismology.</p>

                    </div>
                </div>

                <div class="updates">
                    <h2>Updates</h2>
                    <div class="update-item">
                        <span class="update-date">2025.09</span>
                        <span class="update-content">üéâ We achieved <strong>4th place</strong> out of 203 submissions and 65 participants in the final evaluation of <a href="https://sites.google.com/view/clvision2025/challenge" target="_blank"><strong>ICCV 2025 6th CLVISION Workshop Challenge</strong></a>! Our solution uses dual LoRA and weighted sampling to enhance LLaVA for better adaptability on both upstream and downstream tasks. Challenge report and presentation coming soon!</span>
                    </div>
                    <div class="update-item">
                        <span class="update-date">2025.05</span>
                        <span class="update-content">Our paper <a href="https://arxiv.org/abs/2505.19455" target="_blank"><strong>"MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question Answering"</strong></a> is now available on arXiv!</span>
                    </div>
                </div>
                
                <div class="contact">
                    <p>Email: <a href="mailto:li.xu2@northeastern.edu">li.xu2@northeastern.edu</a></p>
                    <div class="social-links">
                        <a href="https://github.com/xli04" target="_blank"><i class="fab fa-github"></i></a>
                        <a href="https://www.linkedin.com/in/xuli04" target="_blank"><i class="fab fa-linkedin"></i></a>
                        <a href="#"><i class="fab fa-google-scholar"></i></a>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <script src="minimal-script.js"></script>
</body>
</html> 